{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a912ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, filtfilt, resample,lfilter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import scipy.signal as signal\n",
    "import librosa.display\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676c33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Denoising using a low pass filter\n",
    "def apply_low_pass_filter(audio, sampling_rate, cutoff_freq):\n",
    "    nyquist_freq = 0.5 * sampling_rate\n",
    "    normalized_cutoff_freq = cutoff_freq / nyquist_freq\n",
    "    b, a = signal.butter(4, normalized_cutoff_freq, btype='low', analog=False)\n",
    "    denoised_audio = signal.lfilter(b, a, audio)\n",
    "    return denoised_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f8ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling audio\n",
    "def downsample_audio(audio,original_sampling_rate,target_sampling_rate):\n",
    "    resampled_audio = librosa.resample(audio, orig_sr=original_sampling_rate, target_sr=target_sampling_rate)\n",
    "    return resampled_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36757f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio into fixed-length segments\n",
    "def split_audio(audio, segment_length):\n",
    "    num_segments = len(audio) // segment_length\n",
    "    segments = [audio[i*segment_length:(i+1)*segment_length] for i in range(num_segments)]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a9108c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spect_testing(data, sr, filename,i):\n",
    "    # Extract spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=data, sr=sr)\n",
    "\n",
    "    # Convert to decibels\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    # Plot spectrogram\n",
    "    plt.figure(figsize=(1.28,1.28))\n",
    "    librosa.display.specshow(spectrogram_db, sr=sr)\n",
    "    plt.savefig((\"/Users/vaishnavikrovvidi/Desktop/Dataset_A/Test-A/{}_{}.png\").format(filename,i), transparent=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cae65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(audio_path, model_path,filename):\n",
    "    audio, sampling_rate = librosa.load(audio_path, sr=None)\n",
    "    # Denoising\n",
    "    cutoff_frequency = 195\n",
    "    denoised_audio = apply_low_pass_filter(audio, sampling_rate, cutoff_frequency)\n",
    "\n",
    "    # Downsampling\n",
    "    target_sampling_rate = sampling_rate // 10\n",
    "    downsampled_audio = downsample_audio(denoised_audio, sampling_rate, target_sampling_rate)\n",
    "\n",
    "    # Splitting audio\n",
    "    segment_length = target_sampling_rate * 3\n",
    "    segments = split_audio(downsampled_audio, segment_length)\n",
    "    model = keras.models.load_model(model_path)\n",
    "    i=0\n",
    "    \n",
    "    for segment in segments:\n",
    "        save_spect_testing(segment,target_sampling_rate,filename,i)\n",
    "\n",
    "        img=Image.open((\"/Users/vaishnavikrovvidi/Desktop/Dataset_A/Test-A/{}_{}.png\").format(filename,i)).convert('RGB')\n",
    "        img_arr=np.asarray(img)\n",
    "        img_arr=img_arr/255\n",
    "\n",
    "        img_arr = img_arr.reshape(1, 128, 128, 3)\n",
    "        \n",
    "        prediction = model.predict(img_arr)\n",
    "        x=np.argmax(prediction)\n",
    "        confidence = prediction[0, x]\n",
    "        i=i+1\n",
    "\n",
    "#         prediction = model.predict(img_arr)\n",
    "#         x=np.argmax(prediction)\n",
    "\n",
    "        classes={0:'Artifact', 1:'Extrasystole', 2:'Murmur', 3:'Normal'}\n",
    "        print(classes[x],confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "830cb576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 11:56:33.571709: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Extrasystole 0.9407989\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Extrasystole 0.9466342\n"
     ]
    }
   ],
   "source": [
    "audio_path='/Users/vaishnavikrovvidi/Desktop/Extrasystole.wav'\n",
    "model_path='/Users/vaishnavikrovvidi/Heartdisease/heart_resnet_spectro.hdf5'\n",
    "filename='fgq'\n",
    "pred(audio_path, model_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947efce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
